{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from src.utils.preprocess import preprocess_video, split_video, split_audio\n",
    "import librosa\n",
    "from datetime import datetime\n",
    "from src.utils.model import get_audio_model, get_visual_model, find_ckpt\n",
    "from src.utils.transforms import get_video_transforms\n",
    "from src.utils.engine import yaml_search, get_recording_filename, read_frames, get_recording_paths, predict, \\\n",
    "    predict_with_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cwd = f\"{os.getcwd()}/../../src/resources\"\n",
    "run_model = 48\n",
    "# 3434 - ambil sepuluh telepon merah di kantor\n",
    "rid = 3435\n",
    "experiment = yaml_search(f\"{cwd}/experiments/video\", run_model)\n",
    "\n",
    "hparams = experiment[\"hyperparameters\"]\n",
    "config = experiment[\"config\"]\n",
    "data = experiment[\"data\"]\n",
    "\n",
    "seed, batch_size, learning_rate = hparams[\"seed\"], hparams[\"batch_size\"], float(hparams[\"learning_rate\"])\n",
    "model_conf = experiment[\"model\"]\n",
    "config = experiment[\"config\"]\n",
    "data = experiment[\"data\"]\n",
    "transforms = get_video_transforms(data[\"transform\"], data[\"color\"])\n",
    "arr_size = [150, 150]\n",
    "\n",
    "visual_model = get_visual_model(model_conf[\"version\"], learning_rate, model_conf[\"name\"], experiment)\n",
    "audio_model = get_audio_model(data[\"audio_version\"], learning_rate, data[\"audio_run\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, cwd, _type, frames, run_name):\n",
    "    default_ckpt_path = f\"{cwd}/models/ilmsg-{_type}/f{frames}\"\n",
    "    ckpt_filename = find_ckpt(f\"{default_ckpt_path}/{run_name}/\")\n",
    "    ckpt_path = f\"{default_ckpt_path}/{run_name}/{ckpt_filename}\"\n",
    "    model = model.load_from_checkpoint(ckpt_path).cuda()\n",
    "    return model\n",
    "\n",
    "# Load Audio CKPT\n",
    "audio_model = load_model(audio_model, cwd, \"audio\", data[\"frames\"], data[\"audio_run\"])\n",
    "# Load Video CKPT\n",
    "visual_model = load_model(visual_model, cwd, \"video\", data[\"frames\"], model_conf[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "def cvt_25fps(input_file, output_file):\n",
    "    # Load the video clip\n",
    "    clip = VideoFileClip(input_file)\n",
    "    # Set the target frame rate to 25 FPS\n",
    "    target_fps = 25\n",
    "    # Convert the clip to 25 FPS\n",
    "    clip_25fps = clip.set_fps(target_fps)\n",
    "    # Write the converted clip to a new file\n",
    "    clip_25fps.write_videofile(output_file, codec=\"libx264\")\n",
    "    # Close the clip\n",
    "    clip.close()\n",
    "\n",
    "def extract_audio(input_file, output_file):\n",
    "    # Load the video clip\n",
    "    clip = VideoFileClip(input_file)\n",
    "    # Extract the audio from the video\n",
    "    audio = clip.audio\n",
    "    # Save the audio as a WAV file\n",
    "    audio.write_audiofile(output_file, codec=\"pcm_s16le\")\n",
    "    # Close the clip\n",
    "    clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/Jokowi_25FPS.mp4.\n",
      "MoviePy - Writing audio in Jokowi_25FPSTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/Jokowi_25FPS.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/Jokowi_25FPS.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/Jokowi.WAV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Early Preprocessing Video\n",
    "cvt_25fps(\n",
    "    input_file=\"../resources/data/YouTube/Jokowi/Jokowi.mp4\",\n",
    "    output_file=\"../resources/data/YouTube/Jokowi/Jokowi_25FPS.mp4\"\n",
    ")\n",
    "extract_audio(\n",
    "    input_file=\"../resources/data/YouTube/Jokowi/Jokowi.mp4\",\n",
    "    output_file=\"../resources/data/YouTube/Jokowi/Jokowi.WAV\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "person = \"Jokowi\"\n",
    "base_dir = f\"../resources/data/YouTube/{person}\"\n",
    "cut_dir = f\"{base_dir}/cut\"\n",
    "processed_dir = f\"{base_dir}/processed\"\n",
    "Path(processed_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/processed/1.mp4.\n",
      "MoviePy - Writing audio in 1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/processed/1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/processed/1.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/processed/1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/processed/10.mp4.\n",
      "MoviePy - Writing audio in 10TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/processed/10.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/processed/10.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/processed/10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/processed/2.mp4.\n",
      "MoviePy - Writing audio in 2TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/processed/2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/processed/2.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/processed/2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/processed/3.mp4.\n",
      "MoviePy - Writing audio in 3TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/processed/3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/processed/3.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/processed/3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/processed/4.mp4.\n",
      "MoviePy - Writing audio in 4TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/processed/4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/processed/4.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/processed/4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/processed/5.mp4.\n",
      "MoviePy - Writing audio in 5TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/processed/5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/processed/5.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/processed/5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../resources/data/YouTube/Jokowi/processed/9.mp4.\n",
      "MoviePy - Writing audio in 9TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../resources/data/YouTube/Jokowi/processed/9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../resources/data/YouTube/Jokowi/processed/9.mp4\n",
      "MoviePy - Writing audio in ../resources/data/YouTube/Jokowi/processed/9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(cut_dir):\n",
    "    basename = file.split(\".\")[0]\n",
    "    cvt_25fps(\n",
    "        input_file=f\"{cut_dir}/{basename}.mp4\",\n",
    "        output_file=f\"{processed_dir}/{basename}.mp4\"\n",
    "    )\n",
    "    extract_audio(\n",
    "        input_file=f\"{cut_dir}/{basename}.mp4\",\n",
    "        output_file=f\"{processed_dir}/{basename}.wav\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "audios = []\n",
    "for file in os.listdir(cut_dir):\n",
    "    # Load Video & Audio\n",
    "    basename = file.split(\".\")[0]\n",
    "    ori_video, (w,h) = read_frames(f\"{processed_dir}/{basename}.mp4\")\n",
    "    ori_audio, _ = librosa.load(f\"{processed_dir}/{basename}.wav\", sr=16000)\n",
    "    videos.append(ori_video)\n",
    "    audios.append(ori_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_filenames():\n",
    "    # Filenames for Target\n",
    "    dt = datetime.now()\n",
    "    time = int(dt.strftime(\"%Y%m%d%H%M%S\"))\n",
    "    filepath = f\"{cwd}/results\"\n",
    "    filename = f\"{time}\"\n",
    "    filename_prediction = f\"{filename}_Prediction.MP4\"\n",
    "    filepath_prediction = f\"{filepath}/{filename_prediction}\"\n",
    "    filename_latent = f\"{filename}_Latent.MP4\"\n",
    "    filepath_latent = f\"{filepath}/{filename_latent}\"\n",
    "    filename_ori = f\"{filename}_Original.MP4\"\n",
    "    filepath_ori = f\"{filepath}/{filename_ori}\"\n",
    "    return filepath_prediction, filepath_latent, filepath_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.audio.stoi import short_time_objective_intelligibility\n",
    "from torchmetrics.functional.audio.pesq import perceptual_evaluation_speech_quality\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_dlib_pybind11.fhog_object_detector object at 0x000002CAC6FDCCF0> <_dlib_pybind11.shape_predictor object at 0x000002CC7B17AD70>\n",
      "Calculate Centroid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [02:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[574.22330097 243.00970874]\n",
      "{'cx': 574.2233009708738, 'cy': 243.0097087378641}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [02:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 5.28 GiB already allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32md:\\College\\Tugas_Akhir\\ILMSG-Webservice\\src\\notebook\\YouTubeVideo.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m label_batch \u001b[39m=\u001b[39m label_batch\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m label_batch \u001b[39m=\u001b[39m audio_model\u001b[39m.\u001b[39mencoder(label_batch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m (ori_mels, ori_latent, ori_audio), (target_mels, target_latent, target_wav) \u001b[39m=\u001b[39m predict(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     visual_model\u001b[39m=\u001b[39;49mvisual_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     filepaths\u001b[39m=\u001b[39;49m(filepath_prediction, filepath_latent, filepath_ori),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     ori_video\u001b[39m=\u001b[39;49mori_video,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     video_batch\u001b[39m=\u001b[39;49mvideo_batch,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     audio_model\u001b[39m=\u001b[39;49maudio_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     ori_audio\u001b[39m=\u001b[39;49mori_audio,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     label_batch\u001b[39m=\u001b[39;49mlabel_batch\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m pesq \u001b[39m=\u001b[39m perceptual_evaluation_speech_quality(target_wav, ori_audio, \u001b[39m16000\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/College/Tugas_Akhir/ILMSG-Webservice/src/notebook/YouTubeVideo.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m stoi \u001b[39m=\u001b[39m short_time_objective_intelligibility(target_wav, ori_audio, \u001b[39m16000\u001b[39m)\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[1;32md:\\College\\Tugas_Akhir\\ILMSG-Webservice\\src\\notebook\\../..\\src\\utils\\engine.py:202\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(visual_model, video_batch, audio_model, filepaths, ori_video, ori_audio, label_batch)\u001b[0m\n\u001b[0;32m    200\u001b[0m filepath_prediction, filepath_latent, filepath_ori \u001b[39m=\u001b[39m filepaths\n\u001b[0;32m    201\u001b[0m \u001b[39m# Prediction\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m latents \u001b[39m=\u001b[39m visual_model(video_batch)\n\u001b[0;32m    203\u001b[0m target_mels \u001b[39m=\u001b[39m audio_model\u001b[39m.\u001b[39mdecoder(latents)\n\u001b[0;32m    204\u001b[0m target_wav \u001b[39m=\u001b[39m sew_audio(target_mels)\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\College\\Tugas_Akhir\\ILMSG-Webservice\\src\\notebook\\../..\\src\\models\\video\\v2\\Vid2SpeechV46.py:112\u001b[0m, in \u001b[0;36mVid2SpeechV46.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    110\u001b[0m features \u001b[39m=\u001b[39m []\n\u001b[0;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m time_frame \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_frames):\n\u001b[1;32m--> 112\u001b[0m     feature \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpretrained_model(x[:, :, time_frame, :, :])\n\u001b[0;32m    113\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n\u001b[0;32m    114\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(features, \u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torchvision\\models\\efficientnet.py:226\u001b[0m, in \u001b[0;36mFusedMBConv.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 226\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_res_connect:\n\u001b[0;32m    228\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\modules\\activation.py:395\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 395\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msilu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\drago\\miniconda3\\envs\\chen\\lib\\site-packages\\torch\\nn\\functional.py:2058\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2056\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, inplace\u001b[39m=\u001b[39minplace)\n\u001b[0;32m   2057\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2058\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49msilu_(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   2059\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39msilu(\u001b[39minput\u001b[39m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 5.28 GiB already allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "scores[\"PESQ\"] = scores[\"STOI\"] = scores[\"ESTOI\"] = [] \n",
    "# for i in tqdm(range(1, len(videos))):\n",
    "for i in tqdm(range(1, 2)):\n",
    "    filepath_prediction, filepath_latent, filepath_ori = generate_filenames()\n",
    "    ori_video = videos[i]\n",
    "    ori_audio = audios[i]\n",
    "    preprocessed_frames = preprocess_video(\n",
    "        rid=rid,\n",
    "        transforms=transforms,\n",
    "        frames=ori_video,\n",
    "        vid_size=arr_size,\n",
    "        local=False,\n",
    "        to_gray=True\n",
    "    )\n",
    "    # Split Video\n",
    "    video_batch = split_video(\n",
    "        frames=preprocessed_frames,\n",
    "        split_frames=data[\"frames\"],\n",
    "        stride=data[\"frames\"],\n",
    "        total_frames=len(preprocessed_frames)\n",
    "    ).cuda()\n",
    "\n",
    "    # Predict Target for Validation\n",
    "    label_batch = split_audio(\n",
    "        y=ori_audio,\n",
    "        split_frames=data[\"frames\"],\n",
    "        stride=data[\"frames\"],\n",
    "        fps=25,\n",
    "        sr=16000,\n",
    "        total_frames = len(preprocessed_frames)\n",
    "    ).cuda()\n",
    "    label_batch = label_batch.unsqueeze(1)\n",
    "    label_batch = audio_model.encoder(label_batch)\n",
    "\n",
    "    (ori_mels, ori_latent, ori_audio), (target_mels, target_latent, target_wav) = predict(\n",
    "        visual_model=visual_model,\n",
    "        filepaths=(filepath_prediction, filepath_latent, filepath_ori),\n",
    "        ori_video=ori_video,\n",
    "        video_batch=video_batch,\n",
    "        audio_model=audio_model,\n",
    "        ori_audio=ori_audio,\n",
    "        label_batch=label_batch\n",
    "    )\n",
    "    pesq = perceptual_evaluation_speech_quality(target_wav, ori_audio, 16000, \"wb\")\n",
    "    stoi = short_time_objective_intelligibility(target_wav, ori_audio, 16000).float()\n",
    "    estoi = short_time_objective_intelligibility(target_wav, ori_audio, 16000, extended=True).float()\n",
    "    scores[\"PESQ\"].append(pesq)\n",
    "    scores[\"STOI\"].append(stoi)\n",
    "    scores[\"ESTOI\"].append(estoi)\n",
    "    print(\"------------------\")\n",
    "    print(\"PESQ:\", pesq)\n",
    "    print(\"STOI:\", stoi)\n",
    "    print(\"ESTOI:\", estoi)\n",
    "    print(\"------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def save_array_as_image(array, filename):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the array as an image\n",
    "    ax.imshow(array)\n",
    "\n",
    "    # Remove the axis ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Save the figure as an image file\n",
    "    plt.savefig(filename)\n",
    "\n",
    "    # Close the figure\n",
    "    plt.close(fig)\n",
    "\n",
    "array = videos[0][0]  # Replace with your NumPy array\n",
    "filename = \"output_image.png\"\n",
    "save_array_as_image(array, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
